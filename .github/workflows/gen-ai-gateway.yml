name: Gen AI Gateway

on:
  workflow_dispatch:
    inputs:
      enable_token_limits:
        description: How many tokens-per-minute would you like to request? (Please note that requests for tokens above nnn will require approval from the Contoso AI team.)
        type: number
        required: true
        default: 1001
      enable_token_metrics:
        description: Please select which token metrics to enable:
        type: choice
        required: false
        options:
          - 'API ID'
          - 'Operation ID'
          - 'Subscription ID'
env:
  description: This workflow is used to apply the OpenAI Token Limit Policy for your intelligent app. It leverages the Gen AI Gateway to apply Contoso's token limits. The supported models are text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002. The default token limit is XYZ. Please note that requests for tokens above nnn will require approval from the Contoso AI team. 
jobs:
  test:
    runs-on: ubuntu-latest
    outputs:
      outputA: 'hello'
      outputB: 'goodbye'

    steps:
      - name: print
        run: echo "The Gen AI Gateway is now enabled for this application."
