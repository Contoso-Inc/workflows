name: Enable OpenAI Token Limits and Token Metrics

on:
  workflow_dispatch:
    inputs:
      enable_token_limits:
        description: How many tokens-per-minute would you like to request? (Please note that requests for tokens above nnn will require approval from the Contoso AI team.)
        type: number
        required: true
        default: 1001
      enable_default_token_metrics:
        description: The default dimensions for AI Token metrics are API ID, Operation ID, Location ID, and Gateway ID. 
        type: boolean
        required: false
        default: true
      enable_userid_token_metrics:
        description: Select this option to enable the 'User ID' metric dimension. 
        type: boolean
        required: false
        default: false
env:
  description: This workflow is used to apply the default Contoso token limit policy and token metrics. The supported models are text-embedding-3-large, text-embedding-3-small, text-embedding-ada-002. The default token limit is XYZ. Please note that requests for tokens above nnn will require approval from the Contoso AI team. 
jobs:
  enable_gen_ai_gateway:
    runs-on: ubuntu-latest
    outputs:
      outputA: 'hello'
      outputB: 'goodbye'
    steps:
      - name: enable_token_limits
        run: echo "Added token limits to the application"
      - name: enable_metrics
        run: echo "Enable token metrics"
      - name: finished
        run: echo "Token limits and metrics are now enabled for this application."
